{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# KNN\n",
        "## ¿Dónde podemos usar KNN?\n",
        "El algoritmo KNN se puede utilizar para clasificación y para regresión.\n",
        "\n",
        "## ¿Cómo funciona?\n",
        "Aquí tenemos dos clases, A y B y un ejemplo que necesitamos clasificar como A o B según nuestro algoritmo.\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/622/1*P4W0JRPUZKlUR68WlRB3bw.webp\"/></center>\n",
        "\n",
        "## 1. Elegir valor de K\n",
        "El valor de K es el número de vecinos más cercanos que examinaremos con nuestro algoritmo. Puede ser 3, 5, 7 y así sucesivamente. Podemos asignar números pares pero no es recomendable para evitar empates durante la clasificación binaria.\n",
        "\n",
        "## 2. Calcular la distancia entre los ejemplos clasificados y los nuevos ejemplos\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/574/1*KG7Thx7wRJARZCEaH7mKXQ.webp\"/></center>\n",
        "\n",
        "Calcularemos la distancia utilizando la fórmula de la distancia Euclídea.\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/640/1*fW5yVOSIqfoxUswg6lhADQ.webp\"/></center>\n",
        "\n",
        "## 3. Ordenar ascendentemente las distancias y obtener los valores principales de K\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/640/1*2B4-bBLUKK-LRFkFqNsTgA.webp\"/></center>\n",
        "\n",
        "## 4. Averiguamos si los vecinos máximos son de la clase A o B\n",
        "Si son de la clase A lo clasificamos como A, por el contrario será de clase B.\n",
        "\n",
        "# Código Python para KNN desde cero\n",
        "Importamos las librerías y leemos el archivo CSV."
      ],
      "metadata": {
        "id": "zRQpD062cmJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = pd.read_csv(\"iris.csv\")"
      ],
      "metadata": {
        "id": "Imn5k85Ai31j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Llamamos al método **.head()** para ver los datos y al método **.shape()** para ver el tamaño de los datos"
      ],
      "metadata": {
        "id": "MgMKYPADjEii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris.head()"
      ],
      "metadata": {
        "id": "ywqoTPkJjSCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://miro.medium.com/max/640/1*ISDg3ZPR3LpsGtASg-B-eg.webp\"/></center>"
      ],
      "metadata": {
        "id": "J74751aKkVca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris.shape"
      ],
      "metadata": {
        "id": "CV-HCQtwkdOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://miro.medium.com/max/158/1*2MVa4PNsz1GbjVu8zdajUw.webp\"/></center>"
      ],
      "metadata": {
        "id": "Xl6CC3XzkfIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformamos los datos utilizando **iloc** para acceder a los datos requeridos y **.values** para obtener la salida como un array. Almacenamos todas las filas y las 4 primeras columnas en **X** y la columna **especies** en Y."
      ],
      "metadata": {
        "id": "tFcvwHTgknvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = iris.iloc[:, :4].values\n",
        "y = iris['species'].values"
      ],
      "metadata": {
        "id": "1a2lD8a0ll9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como necesitamos probar nuestro modelo debemos separar algunos datos para el testeo.\n",
        "Lo haremos utilizando ***train_test_split*** de la librería ***sklearn***.\n",
        "***test_size=0.2*** significa que utilizaremos el 80% de los datos para entrenar el modelo y 20% para el testeo. Utilizaremos ***random_state*** para obtener la misma división cada vez."
      ],
      "metadata": {
        "id": "PxURdY3dltVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "HEVwAL_qmds4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todos los pasos del pre procesado están listos, ahora creamos el algoritmo.\n",
        "\n",
        "## Paso 1\n",
        "Escribimos una función para calcular la distancia Euclídea. La función es sencilla de entender. Tomamos la diferencia elevándola al cuadrado, sumándolas y finalmente sacando la raíz cuadrada."
      ],
      "metadata": {
        "id": "jUZR-X_Xmnwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def distance(pa, pb):\n",
        "  return np.sum((pa-pb)**2)**0.5"
      ],
      "metadata": {
        "id": "zTD5u2bcnPYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 2\n",
        "Definimos otra función llamada KNN. ***x_query*** es el nuevo ejemplo para el que queremos encontrar la etiqueta/clase."
      ],
      "metadata": {
        "id": "o9pU-3SonXoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def KNN(x, y, x_query, k=5)"
      ],
      "metadata": {
        "id": "jUzd72kOnnQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora requerimos el número de filas para recorrer cada ejemplo en el conjunto de datos y requerimos una lista para almacenar todas las distancias calculadas usando la función de distancia."
      ],
      "metadata": {
        "id": "wUxV-CW8nqkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = x.shape[0]\n",
        "distances = []"
      ],
      "metadata": {
        "id": "MwwrhpyBn98r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el siguiente paso iteramos por todos los ejemplos y calcularemos la distancia usando la función ***distance*** que hemos creado. Le pasaremos ***x_query*** y todos los ejemplos uno por uno. Una vez que obtengamos la distancia añadiremos una tupla de distancia y etiqueta a la lista **distances** previamente creada."
      ],
      "metadata": {
        "id": "1WmGWH9roBg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(m):\n",
        "  dis = distance(x_query, x[i])\n",
        "  distances.append((dis, y[i]))"
      ],
      "metadata": {
        "id": "FObPZCTkoow1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tenemos toda la distancia de todos los puntos desde x_query. Ahora las ordenamos en orden ascendente y seleccionaremos las K distancias principales."
      ],
      "metadata": {
        "id": "SikT_L9ZoxBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distances = sorted(distances)\n",
        "distances = distances[:k]"
      ],
      "metadata": {
        "id": "ZkIB3dRcpPw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el siguiente paso, convertiremos la lista en un array para poder extraer datos facilmente. Extraeremos las etiquetas del array recien creado."
      ],
      "metadata": {
        "id": "Y4OXzFkApVkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distances = np.array(distances)\n",
        "labels = distances[:, 1]"
      ],
      "metadata": {
        "id": "pgl7OJOIqRLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizaremos una función de ***Numpy*** para obtener las etiquetas únicas y su conteo. La imagen muestra un ejemplo de esta función. Recibimos un array([1, 2]), ya que son los únicos elementos en la lista que le hemos pasado como parámetro y recibimos los recuentos de 1 y 2 como array([3, 2])\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/640/1*4XBT-qhAiczPhga7iJ51rw.webp\"/></center>"
      ],
      "metadata": {
        "id": "g75uN1MsqY0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique([1, 2, 1, 2, 1], return_counts=True)"
      ],
      "metadata": {
        "id": "hjie4V5yriHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora utilizaremos esto en nuestro algoritmo. En el segundo paso usamos la función **argmax()** que nos devolverá el índice del valor máximo y cuando lo pasemos a ***uniq_label*** obtendremos la predicción."
      ],
      "metadata": {
        "id": "oJSN2qmOrpP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uniq_label, counts = np.unique(labels, return_counts=True)\n",
        "pred = uniq_label[counts.argmax()]"
      ],
      "metadata": {
        "id": "25cgZg_IsGy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algoritmo completo"
      ],
      "metadata": {
        "id": "mMrVtDr4sVtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def KNN(x, y, x_query, k=5):\n",
        "  m = x.shape[0]\n",
        "  # get 100 values\n",
        "\n",
        "  distances = []\n",
        "\n",
        "  # iterate over all examples\n",
        "  for i in range(m):\n",
        "    dis = distance(x_query, x[i])\n",
        "    print(x[i], x_query)\n",
        "    distances.append((dis, y[i]))\n",
        "\n",
        "  # sort\n",
        "  distances = sorted(distances)\n",
        "\n",
        "  # take top 5\n",
        "  distances = distances[:k]\n",
        "\n",
        "  # convert to numpy to extract data\n",
        "  distances = np.array(distances)\n",
        "\n",
        "  labels = distances[:, 1]\n",
        "\n",
        "  uniq_label, counts = np.unique(labels, return_counts=True)\n",
        "  pred = uniq_label[counts.argmax()]\n",
        "\n",
        "  return (pred)"
      ],
      "metadata": {
        "id": "2nKr2scLsYvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 3\n",
        "Utilizaremos este algoritmo (la función creada) para predecir la etiqueta/clase para el nuevo ejemplo."
      ],
      "metadata": {
        "id": "wfedL8xvtdPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KNN(x_train, y_train, x_test[23], k=7)"
      ],
      "metadata": {
        "id": "GxLXGmpktnKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://miro.medium.com/max/274/1*d-IWBZaffH4Z6owejd3YCA.webp\"/></center>"
      ],
      "metadata": {
        "id": "WBhGTZUwttA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora predecimos etiquetas para todos los datos de test y los almacenamos en una lista."
      ],
      "metadata": {
        "id": "Wu22XwOjt08c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = []\n",
        "for i in range(30):\n",
        "  p = KNN(x_train, y_train, x_test[i], k=7)\n",
        "  prediction.append(p)"
      ],
      "metadata": {
        "id": "WJeMIwPct8vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el último paso, convertiremos la lista en un array y calcularemos la precisión de nuestro algoritmo. Para calcular la precisión compararemos los valores de ***y_test*** con los valores predichos. Usaremos ***sum*** para obtener la cuenta de las predicciones correctas."
      ],
      "metadata": {
        "id": "goQIyyqHuGnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = np.array(prediction)\n",
        "(y_test[:100] == predictions).sum()/len(predictions)"
      ],
      "metadata": {
        "id": "X02eX-2xzqBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La precisión de este modelo es del 96,6%\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/328/1*0836py9r3OjGFZZpFWo3aQ.webp\"/></center>"
      ],
      "metadata": {
        "id": "1-98qrCAz0JW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Código Python para KNN usando scikit-learn (sklearn)\n",
        "Primero importamos KNN classifier. Creamos un objeto llamado ***knn***. Existen varios parámetros que podemos pasarle pero para explicar lo básico sólo le pasaremos ***k***.\n",
        "\n",
        "Para saber más sobre los parámetros de KNN visita [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)."
      ],
      "metadata": {
        "id": "8XKww2NB0ug2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=3)"
      ],
      "metadata": {
        "id": "Xdf70SNI1UGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Llamamos al método ***fit*** y le pasamos ***x_train*** y ***y_train*** como parámetros para el aprendizaje del modelo."
      ],
      "metadata": {
        "id": "rHiHp-ij1dqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "jBBTZZUa1ue9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para la predicción, la clase sklearn nos proporciona un método llamado ***predict***. En el siguiente código, remodelamos la entrada para convertir el vector en un array."
      ],
      "metadata": {
        "id": "8vFPEt1l1xZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn.predict(x_test[23].reshape(1, -1))"
      ],
      "metadata": {
        "id": "vCRalOe52IGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para predecir la clase de un conjunto de datos completo creamos una lista para agregar las clases predichas y luego usar el método de predicción."
      ],
      "metadata": {
        "id": "TkzvcDpY2M4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = []\n",
        "for i in range(30):\n",
        "  p = knn.predict(x_test[i].reshape(1, -1))\n",
        "  prediction.append(p[0])"
      ],
      "metadata": {
        "id": "axdrQOLP2c9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para calcular la precisión compararemos los valores de ***y_test*** con los valores predichos. Usaremos ***sum*** para obtener la cuenta de las predicciones correctas."
      ],
      "metadata": {
        "id": "BJPsv3M62nE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(y_test[:30] == prediction).sum()/len(prediction)"
      ],
      "metadata": {
        "id": "3dz3tZUi3EQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La precisión utilizando Sklearn es del 100%\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/78/1*XPudFA0MTw7UQB4iDQW2RQ.webp\"/></center>\n",
        "\n",
        "# Ventajas y desventajas de KNN\n",
        "## Ventajas\n",
        "*   Fácil implementación\n",
        "*   Sin periodo de entrenamiento\n",
        "\n",
        "## Desventajas\n",
        "*   Sensible al ruido y a datos ausentes\n",
        "*   No funciona bien con una alta dimensionalidad\n",
        "*   No funciona bien con grandes datasets\n",
        "\n"
      ],
      "metadata": {
        "id": "mjp47AP13K08"
      }
    }
  ]
}